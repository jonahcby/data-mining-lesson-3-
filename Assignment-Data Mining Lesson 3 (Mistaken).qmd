---
title: "Probabilistic Learning with Naive Bayes Classification"
format: html
editor: visual
---

Writer : Bruno Santana

Correcter : Jonah Cabay√©

## Setup - Instaling package

```{r}
#install.packages("tm")
#install.packages("wordcloud")
#install.packages("e1071")

library(tidyverse)
library(tm)
library(caret)
library(wordcloud)
library(e1071)
```

## Read data

```{r}
url <- "https://raw.githubusercontent.com/HAN-M3DM-Data-Mining/data-mining-s1y2223-Shake782/master/datasets/NB-fakenews.csv"
rawDF <- read_csv(url)
#head(rawDF)
#view(rawDF)
```

## Data understanding

```{r}
#Removing unecessary columns

keepcolumns <- c("Text", "label")
cleanDF <- rawDF[keepcolumns]
```

```{r}
class(cleanDF$label)

#Replacing binary values for text in "label" column
cleanDF$label[cleanDF$label == 0] <- "Trustworthy"
cleanDF$label[cleanDF$label == 1] <- "Fake news"

cleanDF$label <- cleanDF$label %>% factor %>% relevel("Fake news")
class(cleanDF$label)
```

```{r}
fake_news <- cleanDF %>% filter(label = "Fake news")
trustworthy <- cleanDF %>% filter(label = "Trustworthy")

wordcloud(fake_news$text, max.words = 20, scale = c(4, 0.8), colors= c("indianred1","indianred2","indianred3","indianred"))
wordcloud(trustworthy$text, max.words = 20, scale = c(4, 0.8), colors= c("lightsteelblue1","lightsteelblue2","lightsteelblue3","lightsteelblue"))
```

## Data preparation

```{r}
rawCorpus <- Corpus(VectorSource(cleanDF$text))
inspect(rawCorpus[1:3])
```

```{r}
cleanCorpus <- rawCorpus %>% tm_map(tolower) %>% tm_map(removeNumbers)
```

```{r}
cleanCorpus <- cleanCorpus %>% tm_map(tolower) %>% tm_map(removeWords, stopwords()) %>% tm_map(removePunctuation)
```

```{r}
cleanCorpus <- cleanCorpus %>% tm_map(stripWhitespace)
```

```{r}
tibble(Raw = rawCorpus$content[1:3], Clean = cleanCorpus$content[1:3])
```

```{r}
cleanDTM <- cleanCorpus %>% DocumentTermMatrix
inspect(cleanDTM)
```

```{r}
# Create split indices
set.seed(1234)
trainIndex <- createDataPartition(cleanDF$label, p = .75, 
                                  list = FALSE, 
                                  times = 1)
head(trainIndex)
```

```{r}
# Apply split indices to DF
trainDF <- cleanDF[trainIndex, ]
```

```{r}
testDF <- cleanDF[-trainIndex, ]

# Apply split indices to Corpus
trainCorpus <- cleanCorpus[trainIndex]
testCorpus <- cleanCorpus[-trainIndex]

# Apply split indices to DTM
trainDTM <- cleanDTM[trainIndex, ]
testDTM <- cleanDTM[-trainIndex, ]
```

```{r}
freqWords <- trainDTM %>% findFreqTerms(3000)
trainDTM <-  DocumentTermMatrix(trainCorpus, list(dictionary = freqWords)
testDTM <-  DocumentTermMatrix(testCorpus, list(dictionary = freqWords)
```

```{r}
convert_counts <- function(x) {
  x <- ifelse(x > 0, 1, 0) %>% factor(levels = c(0,1), labels = c("No", "Yes"))
}

nColsDTM <- dim(trainDTM)[2]
trainDTM <- apply(trainDTM, MARGIN = 2, convert_counts)
testDTM <- apply(testDTM, MARGIN = 2, convert_counts)

head(trainDTM[,1:10])
```

## Modeling and Evaluation

```{r}
nbayesModel <-  naiveBayes(trainDTM, trainDF$label, laplace = 1)
```

```{r}
predVec <- predict(nbayesModel, testDTM)
confusionMatrix(predVec, testDF$label, positive = "Fake news", dnn = c("Prediction"))
```
